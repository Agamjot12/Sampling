# ML Sampling Techniques Comparison

This project compares the performance of 5 different machine learning models on 5 different sampling techniques for imbalanced datasets. 

### The sampling techniques used in this project are:

- Random Over-Sampling
- Random Under-Sampling
- SMOTE
- Stratified Sampling
- Systematic Sampling

### The machine learning models used in this project are:

- Logistic Regression
- Random Forest
- Support Vector Machine
- K-Nearest Neighbors
- XGBoost

### The project is implemented in Python using the following libraries:
- numpy
- pandas
- scikit-learn
- imbalanced-learn
- xgboost


### Comparision Table



