# ML Sampling Techniques Comparison

This project compares the performance of 5 different machine learning models on 5 different sampling techniques for imbalanced datasets. 

### The sampling techniques used in this project are:

- Random Over-Sampling
- Random Under-Sampling
- SMOTE
- Stratified Sampling
- Systematic Sampling

### The machine learning models used in this project are:

- Logistic Regression
- Random Forest
- Support Vector Machine
- K-Nearest Neighbors
- XGBoost

### The project is implemented in Python using the following libraries:
- numpy
- pandas
- scikit-learn
- imbalanced-learn
- xgboost


### Comparision Table

<img width="836" alt="Screenshot 2023-02-19 at 6 34 11 PM" src="https://user-images.githubusercontent.com/72341235/219949841-0acc8451-f559-4a01-af4f-4d2c8a5f7529.png">
