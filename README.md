# ML Sampling Techniques Comparison

This project compares the performance of 5 different machine learning models on 5 different sampling techniques for imbalanced datasets. 

### The sampling techniques used in this project are:

- Random Over-Sampling
- Random Under-Sampling
- SMOTE
- Stratified Sampling
- Systematic Sampling

### The machine learning models used in this project are:

- Logistic Regression
- Random Forest
- Support Vector Machine
- K-Nearest Neighbors
- XGBoost

### The project is implemented in Python using the following libraries:
- numpy
- pandas
- scikit-learn
- imbalanced-learn
- xgboost


### Comparision Table

<img width="662" alt="Screenshot 2023-02-20 at 1 11 42 AM" src="https://user-images.githubusercontent.com/72341235/219971437-3799692c-6062-4f87-974e-6a06508e3601.png">


